{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory \n",
    "\n",
    "There are several use cases where it is valuable to maintain a bank of useful facts that can be intelligently added to the context of the agent just before a specific step. The typically use case here is a RAG pattern where a query is used to retrieve relevant information from a database that is then added to the agent's context.\n",
    "\n",
    "\n",
    "AgentChat provides a `Memory` protocol that can be extended to provide this functionality.  The key methods are `query`, `add`, `clear`, and `cleanup`. The `query` method is used to retrieve relevant information from the memory store, the `add` method is used to add new entries to the memory store, the `clear` method is used to clear all entries from the memory store, and the `cleanup` method is used to clean up any resources used by the memory store.\n",
    "\n",
    "\n",
    "## ListMemory\n",
    "\n",
    "ListMemory is a simple list-based memory implementation that uses text similarity matching to retrieve relevant information from the memory store. The similarity score is calculated using the `SequenceMatcher` class from the `difflib` module. The similarity score is calculated between the query text and the content text of each memory entry.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- weather_agent ----------\n",
      "[FunctionCall(id='call_oIYlxvmJ6k9JxfPx96JuDz1G', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 130, Completion tokens: 19]\n",
      "---------- weather_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 degrees and Sunny.', call_id='call_oIYlxvmJ6k9JxfPx96JuDz1G')]\n",
      "---------- weather_agent ----------\n",
      "The weather in New York is 23Â°C and sunny. TERMINATE\n",
      "[Prompt tokens: 172, Completion tokens: 15]\n",
      "---------- Summary ----------\n",
      "Number of messages: 4\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 302\n",
      "Total completion tokens: 34\n",
      "Duration: 1.55 seconds\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.models import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.memory._base_memory import MemoryEntry\n",
    "from autogen_agentchat.task import Console, TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.memory._list_memory import ListMemory, MemoryEntry\n",
    "\n",
    "\n",
    "# create a simple memory item\n",
    "memory = ListMemory()\n",
    "await memory.add(MemoryEntry(content=\"Whenever you are asked for the weather, return it in metric units.\"))\n",
    "\n",
    "\n",
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "    ),\n",
    "    tools=[get_weather],\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "agent_team = RoundRobinGroupChat([weather_agent], termination_condition=TextMentionTermination(\"TERMINATE\"))\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=\"What is the weather in New York?\")\n",
    "await Console(stream);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB Memory (ChromaDB)\n",
    "\n",
    "Similarly, we can implement a memory store that uses a vector database to store and retrieve information.  `ChromaMemory` is a memory implementation that uses ChromaDB to store and retrieve information. ChromaDB is a vector database that is optimized for similarity search.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [MemoryQueryResult(entry=MemoryEntry(content=\"The most important thing about tokyo is that it has the world's busiest railway station - Shinjuku Station.\", metadata={}, timestamp=datetime.datetime(2024, 11, 30, 15, 28, 58, 195846), source='travel_facts'), score=0.5832697153091431)]\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.base import CancellationToken\n",
    "from autogen_ext.models import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.memory._base_memory import MemoryEntry\n",
    "from autogen_agentchat.memory._chroma_memory import ChromaMemory, ChromaMemoryConfig\n",
    "\n",
    "\n",
    "# Initialize memory\n",
    "chroma_memory = ChromaMemory(\n",
    "    name=\"travel_memory\",\n",
    "    config=ChromaMemoryConfig(\n",
    "        collection_name=\"travel_facts\",\n",
    "        # Configure number of results to return instead of similarity threshold\n",
    "        k=1,\n",
    "    ),\n",
    ")\n",
    "# Add some travel-related memories\n",
    "await chroma_memory.add(\n",
    "    MemoryEntry(content=\"Paris is known for the Eiffel Tower and amazing cuisine.\", source=\"travel_guide\")\n",
    ")\n",
    "\n",
    "await chroma_memory.add(\n",
    "    MemoryEntry(\n",
    "        content=\"The most important thing about tokyo is that it has the world's busiest railway station - Shinjuku Station.\",\n",
    "        source=\"travel_facts\",\n",
    "    )\n",
    ")\n",
    "\n",
    "results = await chroma_memory.query(\"Tell me about Tokyo.\")\n",
    "print(len(results), results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Tell me the most important thing about Tokyo.\n",
      "---------- travel_agent ----------\n",
      "One of the most important aspects of Tokyo is that it has the world's busiest railway station, Shinjuku Station. This station serves as a major hub for transportation, with millions of commuters and travelers passing through its complex network of train lines each day. It highlights Tokyo's status as a bustling metropolis with an advanced public transportation system.\n",
      "[Prompt tokens: 72, Completion tokens: 66]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Maximum number of messages 2 reached, current message count: 2\n",
      "Total prompt tokens: 72\n",
      "Total completion tokens: 66\n",
      "Duration: 1.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create agent with memory\n",
    "agent = AssistantAgent(\n",
    "    name=\"travel_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        # api_key=\"your_api_key\"\n",
    "    ),\n",
    "    memory=chroma_memory,\n",
    "    system_message=\"You are a travel expert\",\n",
    ")\n",
    "\n",
    "agent_team = RoundRobinGroupChat([agent], termination_condition=MaxMessageTermination(max_messages=2))\n",
    "stream = agent_team.run_stream(task=\"Tell me the most important thing about Tokyo.\")\n",
    "await Console(stream);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
