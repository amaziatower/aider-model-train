{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory \n",
    "\n",
    "There are several use cases where it is valuable to maintain a bank of useful facts that can be intelligently added to the context of the agent just before a specific step. The typically use case here is a RAG pattern where a query is used to retrieve relevant information from a database that is then added to the agent's context.\n",
    "\n",
    "\n",
    "AgentChat provides a `Memory` protocol that can be extended to provide this functionality.  The key methods are `query`, `add`, `clear`, and `cleanup`. The `query` method is used to retrieve relevant information from the memory store, the `add` method is used to add new entries to the memory store, the `clear` method is used to clear all entries from the memory store, and the `cleanup` method is used to clean up any resources used by the memory store.\n",
    "\n",
    "\n",
    "## ListMemory\n",
    "\n",
    "ListMemory is a simple list-based memory implementation that uses text similarity matching to retrieve relevant information from the memory store. The similarity score is calculated using the `SequenceMatcher` class from the `difflib` module. The similarity score is calculated between the query text and the content text of each memory entry.   \n",
    "\n",
    "In the following example, we will use ListMemory to similate a memory bank of user preferences and explore how it might be used in personalizing the agent's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What is the weather in New York?\n",
      "---------- assistant_agent ----------\n",
      "[FunctionCall(id='call_qNo7mjlNoVNaQzK1B6toXuW5', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "[Prompt tokens: 128, Completion tokens: 20]\n",
      "---------- assistant_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 degrees and Sunny.', call_id='call_qNo7mjlNoVNaQzK1B6toXuW5')]\n",
      "---------- assistant_agent ----------\n",
      "The weather in New York is 23 degrees and Sunny.\n",
      "---------- assistant_agent ----------\n",
      "The weather in New York is 23 degrees Celsius and sunny. TERMINATE\n",
      "[Prompt tokens: 170, Completion tokens: 17]\n",
      "---------- Summary ----------\n",
      "Number of messages: 5\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 298\n",
      "Total completion tokens: 37\n",
      "Duration: 1.97 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What is the weather in New York?', type='TextMessage'), ToolCallRequestEvent(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=128, completion_tokens=20), content=[FunctionCall(id='call_qNo7mjlNoVNaQzK1B6toXuW5', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant_agent', models_usage=None, content=[FunctionExecutionResult(content='The weather in New York is 23 degrees and Sunny.', call_id='call_qNo7mjlNoVNaQzK1B6toXuW5')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='assistant_agent', models_usage=None, content='The weather in New York is 23 degrees and Sunny.', type='ToolCallSummaryMessage'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=170, completion_tokens=17), content='The weather in New York is 23 degrees Celsius and sunny. TERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent \n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.memory._list_memory import ListMemory, MemoryContent, MemoryMimeType\n",
    "\n",
    "# create a simple memory item \n",
    "user_memory = ListMemory()\n",
    "await user_memory.add(MemoryContent(\n",
    "    content=\"The weather should be in metric units\",\n",
    "    mime_type=MemoryMimeType.TEXT\n",
    "))\n",
    "\n",
    "await user_memory.add(MemoryContent(\n",
    "    content=\"Meal recipe must be vegan\",\n",
    "    mime_type=MemoryMimeType.TEXT\n",
    "))\n",
    "\n",
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 degrees and Sunny.\"  \n",
    "\n",
    "assistant_agent = AssistantAgent(\n",
    "    name=\"assistant_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\", \n",
    "    ),\n",
    "    tools=[get_weather], \n",
    "    memory=[user_memory]\n",
    ")\n",
    "  \n",
    "agent_team = RoundRobinGroupChat([assistant_agent], termination_condition = TextMentionTermination(\"TERMINATE\"))\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=\"What is the weather in New York?\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that the weather is returned in Centigrade as stated in the user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Suggest a brief meal recipe\n",
      "---------- assistant_agent ----------\n",
      "Here's a brief vegan meal recipe for you:\n",
      "\n",
      "**Vegan Chickpea Salad Sandwich**\n",
      "\n",
      "**Ingredients:**\n",
      "- 1 can chickpeas, drained and rinsed\n",
      "- 2 tablespoons vegan mayonnaise\n",
      "- 1 tablespoon Dijon mustard\n",
      "- 1 tablespoon lemon juice\n",
      "- Salt and pepper to taste\n",
      "- 1/4 cup diced celery\n",
      "- 1/4 cup diced red onion\n",
      "- 2 tablespoons chopped fresh parsley\n",
      "- 4 slices whole-grain bread\n",
      "- Lettuce leaves and tomato slices (optional)\n",
      "\n",
      "**Instructions:**\n",
      "1. In a bowl, mash the chickpeas with a fork until mostly broken down, but still a bit chunky.\n",
      "2. Stir in the vegan mayonnaise, Dijon mustard, lemon juice, salt, and pepper.\n",
      "3. Add the diced celery, red onion, and chopped parsley. Mix until well combined.\n",
      "4. Layer the chickpea salad on two slices of whole-grain bread. Add lettuce leaves and tomato slices if desired.\n",
      "5. Place the remaining slices of bread on top to form sandwiches. Serve immediately and enjoy! \n",
      "\n",
      "This vegan chickpea salad sandwich is quick to make and perfect for a healthy lunch. TERMINATE\n",
      "[Prompt tokens: 235, Completion tokens: 239]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 235\n",
      "Total completion tokens: 239\n",
      "Duration: 4.66 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Suggest a brief meal recipe', type='TextMessage'), TextMessage(source='assistant_agent', models_usage=RequestUsage(prompt_tokens=235, completion_tokens=239), content=\"Here's a brief vegan meal recipe for you:\\n\\n**Vegan Chickpea Salad Sandwich**\\n\\n**Ingredients:**\\n- 1 can chickpeas, drained and rinsed\\n- 2 tablespoons vegan mayonnaise\\n- 1 tablespoon Dijon mustard\\n- 1 tablespoon lemon juice\\n- Salt and pepper to taste\\n- 1/4 cup diced celery\\n- 1/4 cup diced red onion\\n- 2 tablespoons chopped fresh parsley\\n- 4 slices whole-grain bread\\n- Lettuce leaves and tomato slices (optional)\\n\\n**Instructions:**\\n1. In a bowl, mash the chickpeas with a fork until mostly broken down, but still a bit chunky.\\n2. Stir in the vegan mayonnaise, Dijon mustard, lemon juice, salt, and pepper.\\n3. Add the diced celery, red onion, and chopped parsley. Mix until well combined.\\n4. Layer the chickpea salad on two slices of whole-grain bread. Add lettuce leaves and tomato slices if desired.\\n5. Place the remaining slices of bread on top to form sandwiches. Serve immediately and enjoy! \\n\\nThis vegan chickpea salad sandwich is quick to make and perfect for a healthy lunch. TERMINATE\", type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = agent_team.run_stream(task=\"Suggest a brief meal recipe\")\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB Memory (ChromaDB)\n",
    "\n",
    "Similarly, we can implement a memory store that uses a vector database to store and retrieve information.  `ChromaMemory` is a memory implementation that uses ChromaDB to store and retrieve information. ChromaDB is a vector database that is optimized for similarity search.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [MemoryQueryResult(content=MemoryContent(content=\"The most important thing about tokyo is that it has the world's busiest railway station - Shinjuku Station.\", mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata={}, timestamp=datetime.datetime(2024, 12, 25, 7, 14, 36, 419091), source=None), score=0.5832697153091431)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.memory._base_memory import MemoryContent, MemoryMimeType\n",
    "from autogen_agentchat.memory._chroma_memory import ChromaMemory, ChromaMemoryConfig\n",
    "\n",
    "\n",
    "# Initialize memory\n",
    "chroma_memory = ChromaMemory(\n",
    "    name=\"travel_memory\",\n",
    "    config=ChromaMemoryConfig(\n",
    "        collection_name=\"travel_facts\",\n",
    "        k=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add travel-related memories\n",
    "await chroma_memory.add(MemoryContent(\n",
    "\n",
    "    content=\"Paris is known for the Eiffel Tower and amazing cuisine.\",\n",
    "    mime_type=MemoryMimeType.TEXT\n",
    "\n",
    "))\n",
    "\n",
    "await chroma_memory.add(MemoryContent( \n",
    "    content=\"The most important thing about tokyo is that it has the world's busiest railway station - Shinjuku Station.\",\n",
    "    mime_type=MemoryMimeType.TEXT\n",
    "\n",
    "))\n",
    " \n",
    "\n",
    "# Query needs ContentItem too\n",
    "results = await chroma_memory.query(\n",
    "    MemoryContent(\n",
    "        content=\"Tell me about Tokyo.\",\n",
    "        mime_type=MemoryMimeType.TEXT\n",
    "    )\n",
    ")\n",
    "\n",
    "print(len(results), results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "Tell me the most important thing about Tokyo.\n",
      "---------- travel_agent ----------\n",
      "One of the most important aspects of Tokyo is its status as a major global hub for culture, technology, and commerce. A notable highlight is Shinjuku Station, which holds the title of the world's busiest railway station. This station is emblematic of Tokyo's extensive and efficient public transportation network that seamlessly connects millions of residents and tourists across the city and beyond. This sophisticated infrastructure is a reflection of Tokyo's dynamic urban environment, showcasing its blend of traditional and modern elements in architecture, culture, and lifestyle.\n",
      "[Prompt tokens: 62, Completion tokens: 102]\n",
      "---------- Summary ----------\n",
      "Number of messages: 2\n",
      "Finish reason: Maximum number of messages 2 reached, current message count: 2\n",
      "Total prompt tokens: 62\n",
      "Total completion tokens: 102\n",
      "Duration: 1.73 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create agent with memory\n",
    "agent = AssistantAgent(\n",
    "    name=\"travel_agent\",\n",
    "    model_client=OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o\",\n",
    "        # api_key=\"your_api_key\"\n",
    "    ),\n",
    "    memory=chroma_memory,\n",
    "    system_message=\"You are a travel expert\"\n",
    ")\n",
    "\n",
    "agent_team = RoundRobinGroupChat([agent], termination_condition = MaxMessageTermination(max_messages=2))\n",
    "stream = agent_team.run_stream(task=\"Tell me the most important thing about Tokyo.\")\n",
    "await Console(stream);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
