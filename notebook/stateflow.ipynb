{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StateFlow: Build Workflows through State-Oriented Actions\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. In this notebook, we introduce the StateFlow feature, which allows you to build workflows with AutoGen agents from a state-oriented perspective.\n",
    "\n",
    "\n",
    "## Construct a StateFlow model\n",
    "To construct a StateFlow model, we need to inherit the `StateFlow` class and define the following variables:\n",
    "- `self.states`: a dictionary of state name and a sequence of actions to be executed in that state.    \n",
    "An action can be:\n",
    "    - a function that takes in a list of messages and returns a string or a dict. \n",
    "    - an `ConversableAgent` object that has `generate_reply` and `reset` method. `reset` will be called in `StateFlow.run()`.\n",
    "    - a str tht will be converted to a dict {'content': str, 'role': 'user'} to be appended to context history.\n",
    "    - a dict following OpenAI message format, will be appended to context history.\n",
    "- `self.initial_state`: the initial state of the workflow.\n",
    "- `self.final_states`: a list of states that indicate the end of the workflow. Note there can be multiple final states.\n",
    "- `self.transitions`: a dictionary of state name and a transition function to determine the next state.\n",
    "There are two types of transitions:\n",
    "    - static string matching: Check whether the last message contains a string, for example, \"exitcode: 1\".\n",
    "    - use an LLM to determine the next state: Instruct an LLM to determine the current state. For example, whether the problem is solved based on the history (or last message). You still need to instruct the LM to generate responses like \"Yes\" or \"No\" and match the response.\n",
    "- `self.max_transitions`: the maximum number of transitions allowed.\n",
    "\n",
    "```python\n",
    "# Example of a simple workflow\n",
    "class ResearchFlow(stateflow.StateFlow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # coder, executor, and scientist are AutoGen agents\n",
    "        self.states = {\n",
    "            \"init\": [],\n",
    "            \"retrieve\": [coder, executor], # execute code to retrieve papers\n",
    "            \"research\": [scientist],\n",
    "            \"end\": [],            \n",
    "        }\n",
    "        self.initial_state = \"init\"\n",
    "        self.final_states = [\"end\"]\n",
    "        self.transitions = {\n",
    "            \"init\": \"retrieve\",\n",
    "            \"retrieve\": lambda messages: \"retrieve\" if \"exitcode: 1\" in messages[-1][\"content\"] else \"research\",\n",
    "            \"research\": \"end\",\n",
    "            \"end\": \"end\",\n",
    "        }\n",
    "        self.max_transitions = 10\n",
    "    \n",
    "\n",
    "    def output_extraction(self, messages):\n",
    "        \"\"\"Overwrite this message to extract the output from a list of messages when the workflow ends.\n",
    "        Default is to return the full list of messages.\n",
    "\n",
    "        Example:\n",
    "            - return messages[-1][\"content\"]\n",
    "            - return messages[-1][\"content\"].split(\"FINAL ANSWER:\")[-1].strip()\n",
    "        \"\"\"\n",
    "        pass\n",
    "```\n",
    "\n",
    "## Run the StateFlow model\n",
    "Call `StateFlow.run()` to start the workflow. The method will first reset the states and transitions, including stateful `Agent` in states. Then it executes the workflow until it reaches a final state or the maximum number of transitions is reached. The method returns the output of the workflow.\n",
    "```python\n",
    "# Example\n",
    "output = research.run(task=\"Topic: LLM applications papers from last week. Requirement: 5 - 10 papers from different domains.\", verbose=True)\n",
    "```\n",
    "\n",
    "\n",
    "## Requirements\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install `pyautogen`:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt-4-1106-preview\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{=mdx}\n",
    ":::tip\n",
    "Learn more about configuring LLMs for agents [here](/docs/llm_configuration).\n",
    ":::\n",
    "````\n",
    "\n",
    "## Example 1: A simple workflow for research\n",
    "\n",
    "<!-- ![SF_Example_1](./sf_example_1.png) -->\n",
    "<figure>\n",
    "    <img src=\"./sf_example_1.png\"  width=\"700\"\n",
    "         alt=\"SF_Example_1\">\n",
    "</figure>\n",
    "\n",
    "Here is a simple workflow for research:\n",
    "The Coder will write code to retrieve papers from the internet. The code will be executed by executor. \n",
    "If code failed, the code will be revised by the engineer and executed again. \n",
    "When the code is executed successfully, the scientist will read the papers and write a summary.\n",
    "\n",
    "\n",
    "We define the following agents:\n",
    "- Coder: Retrieve papers from the internet by writing code.\n",
    "- Executor: Execute the code.\n",
    "- Scientist: Read the papers and write a summary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib import stateflow\n",
    "\n",
    "gpt4_config = {\n",
    "    \"cache_seed\": 42,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"\"\"You are the Coder. Given a topic, write code to retrieve related papers from the arXiv API, print their title, authors, abstract, and link.\n",
    "You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "\"\"\",\n",
    ")\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the Coder and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"paper\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "\n",
    "scientist = autogen.AssistantAgent(\n",
    "    name=\"Scientist\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"\"\"You are the Scientist. Please categorize papers after seeing their abstracts printed and create a markdown table with Domain, Title, Authors, Summary and Link\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "class ResearchFlow(stateflow.StateFlow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # define states and a sequence of actions in each state\n",
    "        # an action can be \n",
    "        # 1. Dict (in the form of message with key \"content\" and \"role\")\n",
    "        # 2. an Agent class, should have generate_reply and reset method.\n",
    "        # 3. an function that takes in a list of messages and return a Dict\n",
    "        self.states = {\n",
    "            \"init\": [],\n",
    "            \"retrieve\": [coder, executor],\n",
    "            \"research\": [scientist],\n",
    "            \"end\": [],            \n",
    "        }\n",
    "        # define initial and final states\n",
    "        self.initial_state = \"init\"\n",
    "        self.final_states = [\"end\"]\n",
    "\n",
    "        # define state transitions\n",
    "        # either a function that takes in a list of messages and returns the next state, or a string that represents the next state\n",
    "        self.transitions = {\n",
    "            \"init\": \"retrieve\",\n",
    "            \"retrieve\": lambda messages: \"retrieve\" if \"exitcode: 1\" in messages[-1][\"content\"] else \"research\",\n",
    "            \"research\": \"end\",\n",
    "            \"end\": \"end\",\n",
    "        }\n",
    "\n",
    "        # set the maximum number of transitions\n",
    "        self.max_transitions = 10\n",
    "\n",
    "    def output_extraction(self, messages):\n",
    "        # override the post processing method, this method is called after the state machine finishes to generate the final output\n",
    "        return messages[-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m*********State init*********\u001b[0m\n",
      "\u001b[34m*********State execute*********\u001b[0m\n",
      "\u001b[33mOutput 1 (Engineer):\u001b[0m\n",
      "To retrieve related papers from the arXiv API, we can use Python with the `requests` library to send a query to the API and then parse the response to extract the required information. Below is a Python script that does this for the topic \"LLM applications\" (assuming LLM stands for Large Language Models), and it will retrieve 5 to 10 papers from different domains that were submitted in the last week.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from datetime import datetime, timedelta\n",
      "import feedparser\n",
      "\n",
      "# Define the base URL for the arXiv API\n",
      "ARXIV_API_URL = \"http://export.arxiv.org/api/query?\"\n",
      "\n",
      "# Define the search parameters\n",
      "search_query = \"all:\\\"LLM applications\\\"\"\n",
      "start = 0\n",
      "max_results = 10\n",
      "sort_by = \"submittedDate\"\n",
      "sort_order = \"descending\"\n",
      "\n",
      "# Calculate the date one week ago from today\n",
      "one_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
      "\n",
      "# Construct the query\n",
      "query = f\"search_query={search_query}&start={start}&max_results={max_results}&sortBy={sort_by}&sortOrder={sort_order}&submittedDateRange={one_week_ago}-\"\n",
      "\n",
      "# Send the request to the arXiv API\n",
      "response = requests.get(ARXIV_API_URL + query)\n",
      "\n",
      "# Parse the response using feedparser\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Print the title, authors, abstract, and link of each entry\n",
      "for entry in feed.entries:\n",
      "    print(\"Title:\", entry.title)\n",
      "    print(\"Authors:\", ', '.join(author.name for author in entry.authors))\n",
      "    print(\"Abstract:\", entry.summary)\n",
      "    print(\"Link:\", entry.link)\n",
      "    print(\"\\n---\\n\")\n",
      "\n",
      "# Check if we have at least 5 papers, if not, adjust the date range and try again\n",
      "if len(feed.entries) < 5:\n",
      "    print(f\"Only {len(feed.entries)} papers found. Adjusting the date range to include more papers.\")\n",
      "    # You can adjust the date range or other parameters here to broaden the search\n",
      "```\n",
      "\n",
      "This script will print the title, authors, abstract, and link for each paper related to \"LLM applications\" from the last week. If fewer than 5 papers are found, it will notify you, and you can adjust the date range or other parameters to broaden the search. Please note that the arXiv API might have limitations on the number of requests you can make per time period, so use this script responsibly.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mOutput 2 (Executor):\u001b[0m\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title: Political Compass or Spinning Arrow? Towards More Meaningful Evaluations\n",
      "  for Values and Opinions in Large Language Models\n",
      "Authors: Paul Röttger, Valentin Hofmann, Valentina Pyatkin, Musashi Hinck, Hannah Rose Kirk, Hinrich Schütze, Dirk Hovy\n",
      "Abstract: Much recent work seeks to evaluate values and opinions in large language\n",
      "models (LLMs) using multiple-choice surveys and questionnaires. Most of this\n",
      "work is motivated by concerns around real-world LLM applications. For example,\n",
      "politically-biased LLMs may subtly influence society when they are used by\n",
      "millions of people. Such real-world concerns, however, stand in stark contrast\n",
      "to the artificiality of current evaluations: real users do not typically ask\n",
      "LLMs survey questions. Motivated by this discrepancy, we challenge the\n",
      "prevailing constrained evaluation paradigm for values and opinions in LLMs and\n",
      "explore more realistic unconstrained evaluations. As a case study, we focus on\n",
      "the popular Political Compass Test (PCT). In a systematic review, we find that\n",
      "most prior work using the PCT forces models to comply with the PCT's\n",
      "multiple-choice format. We show that models give substantively different\n",
      "answers when not forced; that answers change depending on how models are\n",
      "forced; and that answers lack paraphrase robustness. Then, we demonstrate that\n",
      "models give different answers yet again in a more realistic open-ended answer\n",
      "setting. We distill these findings into recommendations and open challenges in\n",
      "evaluating values and opinions in LLMs.\n",
      "Link: http://arxiv.org/abs/2402.16786v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Large Language Models as Urban Residents: An LLM Agent Framework for\n",
      "  Personal Mobility Generation\n",
      "Authors: Jiawei Wang, Renhe Jiang, Chuang Yang, Zengqing Wu, Makoto Onizuka, Ryosuke Shibasaki, Chuan Xiao\n",
      "Abstract: This paper introduces a novel approach using Large Language Models (LLMs)\n",
      "integrated into an agent framework for flexible and efficient personal mobility\n",
      "generation. LLMs overcome the limitations of previous models by efficiently\n",
      "processing semantic data and offering versatility in modeling various tasks.\n",
      "Our approach addresses the critical need to align LLMs with real-world urban\n",
      "mobility data, focusing on three research questions: aligning LLMs with rich\n",
      "activity data, developing reliable activity generation strategies, and\n",
      "exploring LLM applications in urban mobility. The key technical contribution is\n",
      "a novel LLM agent framework that accounts for individual activity patterns and\n",
      "motivations, including a self-consistency approach to align LLMs with\n",
      "real-world activity data and a retrieval-augmented strategy for interpretable\n",
      "activity generation. In experimental studies, comprehensive validation is\n",
      "performed using real-world data. This research marks the pioneering work of\n",
      "designing an LLM agent framework for activity generation based on real-world\n",
      "human activity data, offering a promising tool for urban mobility analysis.\n",
      "Link: http://arxiv.org/abs/2402.14744v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: An Evaluation of Large Language Models in Bioinformatics Research\n",
      "Authors: Hengchuang Yin, Zhonghui Gu, Fanhao Wang, Yiparemu Abuduhaibaier, Yanqiao Zhu, Xinming Tu, Xian-Sheng Hua, Xiao Luo, Yizhou Sun\n",
      "Abstract: Large language models (LLMs) such as ChatGPT have gained considerable\n",
      "interest across diverse research communities. Their notable ability for text\n",
      "completion and generation has inaugurated a novel paradigm for\n",
      "language-interfaced problem solving. However, the potential and efficacy of\n",
      "these models in bioinformatics remain incompletely explored. In this work, we\n",
      "study the performance LLMs on a wide spectrum of crucial bioinformatics tasks.\n",
      "These tasks include the identification of potential coding regions, extraction\n",
      "of named entities for genes and proteins, detection of antimicrobial and\n",
      "anti-cancer peptides, molecular optimization, and resolution of educational\n",
      "bioinformatics problems. Our findings indicate that, given appropriate prompts,\n",
      "LLMs like GPT variants can successfully handle most of these tasks. In\n",
      "addition, we provide a thorough analysis of their limitations in the context of\n",
      "complicated bioinformatics tasks. In conclusion, we believe that this work can\n",
      "provide new perspectives and motivate future research in the field of LLMs\n",
      "applications, AI for Science and bioinformatics.\n",
      "Link: http://arxiv.org/abs/2402.13714v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Privacy-Preserving Instructions for Aligning Large Language Models\n",
      "Authors: Da Yu, Peter Kairouz, Sewoong Oh, Zheng Xu\n",
      "Abstract: Service providers of large language model (LLM) applications collect user\n",
      "instructions in the wild and use them in further aligning LLMs with users'\n",
      "intentions. These instructions, which potentially contain sensitive\n",
      "information, are annotated by human workers in the process. This poses a new\n",
      "privacy risk not addressed by the typical private optimization. To this end, we\n",
      "propose using synthetic instructions to replace real instructions in data\n",
      "annotation and model fine-tuning. Formal differential privacy is guaranteed by\n",
      "generating those synthetic instructions using privately fine-tuned generators.\n",
      "Crucial in achieving the desired utility is our novel filtering algorithm that\n",
      "matches the distribution of the synthetic instructions to that of the real\n",
      "ones. In both supervised fine-tuning and reinforcement learning from human\n",
      "feedback, our extensive experiments demonstrate the high utility of the final\n",
      "set of synthetic instructions by showing comparable results to real\n",
      "instructions. In supervised fine-tuning, models trained with private synthetic\n",
      "instructions outperform leading open-source models such as Vicuna.\n",
      "Link: http://arxiv.org/abs/2402.13659v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in\n",
      "  Conversations with the Tabletop Robot Haru\n",
      "Authors: Zining Wang, Paul Reisert, Eric Nichols, Randy Gomez\n",
      "Abstract: Social robots aim to establish long-term bonds with humans through engaging\n",
      "conversation. However, traditional conversational approaches, reliant on\n",
      "scripted interactions, often fall short in maintaining engaging conversations.\n",
      "This paper addresses this limitation by integrating large language models\n",
      "(LLMs) into social robots to achieve more dynamic and expressive conversations.\n",
      "We introduce a fully-automated conversation system that leverages LLMs to\n",
      "generate robot responses with expressive behaviors, congruent with the robot's\n",
      "personality. We incorporate robot behavior with two modalities: 1) a\n",
      "text-to-speech (TTS) engine capable of various delivery styles, and 2) a\n",
      "library of physical actions for the robot. We develop a custom,\n",
      "state-of-the-art emotion recognition model to dynamically select the robot's\n",
      "tone of voice and utilize emojis from LLM output as cues for generating robot\n",
      "actions. A demo of our system is available here. To illuminate design and\n",
      "implementation issues, we conduct a pilot study where volunteers chat with a\n",
      "social robot using our proposed system, and we analyze their feedback,\n",
      "conducting a rigorous error analysis of chat transcripts. Feedback was\n",
      "overwhelmingly positive, with participants commenting on the robot's empathy,\n",
      "helpfulness, naturalness, and entertainment. Most negative feedback was due to\n",
      "automatic speech recognition (ASR) errors which had limited impact on\n",
      "conversations. However, we observed a small class of errors, such as the LLM\n",
      "repeating itself or hallucinating fictitious information and human responses,\n",
      "that have the potential to derail conversations, raising important issues for\n",
      "LLM application.\n",
      "Link: http://arxiv.org/abs/2402.11571v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots\n",
      "  in Ophthalmology and LLM-based evaluation using GPT-4\n",
      "Authors: Ting Fang Tan, Kabilan Elangovan, Liyuan Jin, Yao Jie, Li Yong, Joshua Lim, Stanley Poh, Wei Yan Ng, Daniel Lim, Yuhe Ke, Nan Liu, Daniel Shu Wei Ting\n",
      "Abstract: Purpose: To assess the alignment of GPT-4-based evaluation to human clinician\n",
      "experts, for the evaluation of responses to ophthalmology-related patient\n",
      "queries generated by fine-tuned LLM chatbots. Methods: 400 ophthalmology\n",
      "questions and paired answers were created by ophthalmologists to represent\n",
      "commonly asked patient questions, divided into fine-tuning (368; 92%), and\n",
      "testing (40; 8%). We find-tuned 5 different LLMs, including LLAMA2-7b,\n",
      "LLAMA2-7b-Chat, LLAMA2-13b, and LLAMA2-13b-Chat. For the testing dataset,\n",
      "additional 8 glaucoma QnA pairs were included. 200 responses to the testing\n",
      "dataset were generated by 5 fine-tuned LLMs for evaluation. A customized\n",
      "clinical evaluation rubric was used to guide GPT-4 evaluation, grounded on\n",
      "clinical accuracy, relevance, patient safety, and ease of understanding. GPT-4\n",
      "evaluation was then compared against ranking by 5 clinicians for clinical\n",
      "alignment. Results: Among all fine-tuned LLMs, GPT-3.5 scored the highest\n",
      "(87.1%), followed by LLAMA2-13b (80.9%), LLAMA2-13b-chat (75.5%),\n",
      "LLAMA2-7b-Chat (70%) and LLAMA2-7b (68.8%) based on the GPT-4 evaluation. GPT-4\n",
      "evaluation demonstrated significant agreement with human clinician rankings,\n",
      "with Spearman and Kendall Tau correlation coefficients of 0.90 and 0.80\n",
      "respectively; while correlation based on Cohen Kappa was more modest at 0.50.\n",
      "Notably, qualitative analysis and the glaucoma sub-analysis revealed clinical\n",
      "inaccuracies in the LLM-generated responses, which were appropriately\n",
      "identified by the GPT-4 evaluation. Conclusion: The notable clinical alignment\n",
      "of GPT-4 evaluation highlighted its potential to streamline the clinical\n",
      "evaluation of LLM chatbot responses to healthcare-related queries. By\n",
      "complementing the existing clinician-dependent manual grading, this efficient\n",
      "and automated evaluation could assist the validation of future developments in\n",
      "LLM applications for healthcare.\n",
      "Link: http://arxiv.org/abs/2402.10083v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Unmemorization in Large Language Models via Self-Distillation and\n",
      "  Deliberate Imagination\n",
      "Authors: Yijiang River Dong, Hongzhou Lin, Mikhail Belkin, Ramon Huerta, Ivan Vulić\n",
      "Abstract: While displaying impressive generation capabilities across many tasks, Large\n",
      "Language Models (LLMs) still struggle with crucial issues of privacy violation\n",
      "and unwanted exposure of sensitive data. This raises an essential question: how\n",
      "should we prevent such undesired behavior of LLMs while maintaining their\n",
      "strong generation and natural language understanding (NLU) capabilities? In\n",
      "this work, we introduce a novel approach termed deliberate imagination in the\n",
      "context of LLM unlearning. Instead of trying to forget memorized data, we\n",
      "employ a self-distillation framework, guiding LLMs to deliberately imagine\n",
      "alternative scenarios. As demonstrated in a wide range of experiments, the\n",
      "proposed method not only effectively unlearns targeted text but also preserves\n",
      "the LLMs' capabilities in open-ended generation tasks as well as in NLU tasks.\n",
      "Our results demonstrate the usefulness of this approach across different models\n",
      "and sizes, and also with parameter-efficient fine-tuning, offering a novel\n",
      "pathway to addressing the challenges with private and sensitive data in LLM\n",
      "applications.\n",
      "Link: http://arxiv.org/abs/2402.10052v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Anchor-based Large Language Models\n",
      "Authors: Jianhui Pang, Fanghua Ye, Derek F. Wong, Longyue Wang\n",
      "Abstract: Large language models (LLMs) predominantly employ decoder-only transformer\n",
      "architectures, necessitating the retention of keys/values information for\n",
      "historical tokens to provide contextual information and avoid redundant\n",
      "computation. However, the substantial size and parameter volume of these LLMs\n",
      "require massive GPU memory. This memory demand increases with the length of the\n",
      "input text, leading to an urgent need for more efficient methods of information\n",
      "storage and processing. This study introduces Anchor-based LLMs (AnLLMs), which\n",
      "utilize an innovative anchor-based self-attention network (AnSAN) and also an\n",
      "anchor-based inference strategy. This approach enables LLMs to compress\n",
      "sequence information into an anchor token, reducing the keys/values cache and\n",
      "enhancing inference efficiency. Experiments on question-answering benchmarks\n",
      "reveal that AnLLMs maintain similar accuracy levels while achieving up to 99%\n",
      "keys/values cache reduction and up to 3.5 times faster inference. Despite a\n",
      "minor compromise in accuracy, the substantial enhancements of AnLLMs employing\n",
      "the AnSAN technique in resource utilization and computational efficiency\n",
      "underscore their potential for practical LLM applications.\n",
      "Link: http://arxiv.org/abs/2402.07616v2\n",
      "\n",
      "---\n",
      "\n",
      "Title: T-RAG: Lessons from the LLM Trenches\n",
      "Authors: Masoomali Fatehkia, Ji Kim Lucas, Sanjay Chawla\n",
      "Abstract: Large Language Models (LLM) have shown remarkable language capabilities\n",
      "fueling attempts to integrate them into applications across a wide range of\n",
      "domains. An important application area is question answering over private\n",
      "enterprise documents where the main considerations are data security, which\n",
      "necessitates applications that can be deployed on-prem, limited computational\n",
      "resources and the need for a robust application that correctly responds to\n",
      "queries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent\n",
      "framework for building LLM-based applications. While building a RAG is\n",
      "relatively straightforward, making it robust and a reliable application\n",
      "requires extensive customization and relatively deep knowledge of the\n",
      "application domain. We share our experiences building and deploying an LLM\n",
      "application for question answering over private organizational documents. Our\n",
      "application combines the use of RAG with a finetuned open-source LLM.\n",
      "Additionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure\n",
      "to represent entity hierarchies within the organization. This is used to\n",
      "generate a textual description to augment the context when responding to user\n",
      "queries pertaining to entities within the organization's hierarchy. Our\n",
      "evaluations show that this combination performs better than a simple RAG or\n",
      "finetuning implementation. Finally, we share some lessons learned based on our\n",
      "experiences building an LLM application for real-world use.\n",
      "Link: http://arxiv.org/abs/2402.07483v1\n",
      "\n",
      "---\n",
      "\n",
      "Title: Task Supportive and Personalized Human-Large Language Model Interaction:\n",
      "  A User Study\n",
      "Authors: Ben Wang, Jiqun Liu, Jamshed Karimnazarov, Nicolas Thompson\n",
      "Abstract: Large language model (LLM) applications, such as ChatGPT, are a powerful tool\n",
      "for online information-seeking (IS) and problem-solving tasks. However, users\n",
      "still face challenges initializing and refining prompts, and their cognitive\n",
      "barriers and biased perceptions further impede task completion. These issues\n",
      "reflect broader challenges identified within the fields of IS and interactive\n",
      "information retrieval (IIR). To address these, our approach integrates task\n",
      "context and user perceptions into human-ChatGPT interactions through prompt\n",
      "engineering. We developed a ChatGPT-like platform integrated with supportive\n",
      "functions, including perception articulation, prompt suggestion, and\n",
      "conversation explanation. Our findings of a user study demonstrate that the\n",
      "supportive functions help users manage expectations, reduce cognitive loads,\n",
      "better refine prompts, and increase user engagement. This research enhances our\n",
      "comprehension of designing proactive and user-centric systems with LLMs. It\n",
      "offers insights into evaluating human-LLM interactions and emphasizes potential\n",
      "challenges for under served users.\n",
      "Link: http://arxiv.org/abs/2402.06170v1\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m*********State research*********\u001b[0m\n",
      "\u001b[33mOutput 3 (Scientist):\u001b[0m\n",
      "Based on the provided code output, here is a markdown table categorizing the papers by their domain, along with their titles, authors, summaries, and links:\n",
      "\n",
      "| Domain | Title | Authors | Summary | Link |\n",
      "|--------|-------|---------|---------|------|\n",
      "| Ethics/Policy | Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models | Paul Röttger, et al. | Evaluates values and opinions in LLMs using the Political Compass Test (PCT) and suggests more realistic unconstrained evaluations. | [Link](http://arxiv.org/abs/2402.16786v1) |\n",
      "| Urban Mobility | Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation | Jiawei Wang, et al. | Introduces an LLM agent framework for personal mobility generation, aligning LLMs with real-world urban mobility data. | [Link](http://arxiv.org/abs/2402.14744v1) |\n",
      "| Bioinformatics | An Evaluation of Large Language Models in Bioinformatics Research | Hengchuang Yin, et al. | Studies the performance of LLMs on bioinformatics tasks and analyzes their limitations in the context of complicated tasks. | [Link](http://arxiv.org/abs/2402.13714v1) |\n",
      "| Privacy | Privacy-Preserving Instructions for Aligning Large Language Models | Da Yu, et al. | Proposes using synthetic instructions to replace real instructions in data annotation and model fine-tuning to ensure privacy. | [Link](http://arxiv.org/abs/2402.13659v1) |\n",
      "| Human-Robot Interaction | Ain't Misbehavin' -- Using LLMs to Generate Expressive Robot Behavior in Conversations with the Tabletop Robot Haru | Zining Wang, et al. | Integrates LLMs into social robots to generate dynamic and expressive conversations, enhancing robot-human interaction. | [Link](http://arxiv.org/abs/2402.11571v1) |\n",
      "| Ophthalmology | Fine-tuning Large Language Model (LLM) Artificial Intelligence Chatbots in Ophthalmology and LLM-based evaluation using GPT-4 | Ting Fang Tan, et al. | Assesses the alignment of GPT-4-based evaluation to human clinician experts for evaluating LLM chatbot responses in ophthalmology. | [Link](http://arxiv.org/abs/2402.10083v1) |\n",
      "| Data Privacy | Unmemorization in Large Language Models via Self-Distillation and Deliberate Imagination | Yijiang River Dong, et al. | Introduces a novel approach for LLM unlearning to prevent privacy violation while maintaining generation and NLU capabilities. | [Link](http://arxiv.org/abs/2402.10052v1) |\n",
      "| Computational Efficiency | Anchor-based Large Language Models | Jianhui Pang, et al. | Proposes Anchor-based LLMs (AnLLMs) to reduce memory demand and enhance inference efficiency while maintaining accuracy. | [Link](http://arxiv.org/abs/2402.07616v2) |\n",
      "| Information Retrieval | T-RAG: Lessons from the LLM Trenches | Masoomali Fatehkia, et al. | Shares experiences building and deploying an LLM application for question answering over private organizational documents. | [Link](http://arxiv.org/abs/2402.07483v1) |\n",
      "| Human-Computer Interaction | Task Supportive and Personalized Human-Large Language Model Interaction: A User Study | Ben Wang, et al. | Studies human-ChatGPT interactions and develops supportive functions to help users manage expectations and refine prompts. | [Link](http://arxiv.org/abs/2402.06170v1) |\n",
      "\n",
      "Please note that the domains are inferred from the context of the abstracts and may not perfectly reflect the authors' intended categorization.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "research = ResearchFlow()\n",
    "output = research.run(task=\"Topic: LLM applications papers from last week. Requirement: 5 - 10 papers from different domains.\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
