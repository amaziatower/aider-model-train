{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import rich\n",
    "except ModuleNotFoundError as e:\n",
    "    raise RuntimeError(\n",
    "        \"You probably either forgot to install the dependencies \"\n",
    "        \"or forgot to activate your conda or virtual environment.\"\n",
    "    ) from e\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import traceback\n",
    "from typing import Any, Dict, List, Optional\n",
    "import rich.console\n",
    "import rich.markdown\n",
    "import rich.panel\n",
    "import rich.markdown\n",
    "\n",
    "try:\n",
    "    from rich_argparse import RichHelpFormatter\n",
    "except ImportError:\n",
    "    msg = (\n",
    "        \"Please install the rich_argparse package with `pip install rich_argparse`.\"\n",
    "    )\n",
    "    raise ImportError(msg)\n",
    "import yaml\n",
    "from rich.markdown import Markdown\n",
    "from dataclasses import dataclass\n",
    "from getpass import getuser\n",
    "from pathlib import Path\n",
    "from rich.logging import RichHandler\n",
    "from simple_parsing import parse\n",
    "from simple_parsing.helpers.serialization.serializable import FrozenSerializable\n",
    "from simple_parsing.helpers.flatten import FlattenedAccess\n",
    "from sweagent import (\n",
    "    Agent,\n",
    "    AgentArguments,\n",
    "    EnvironmentArguments,\n",
    "    ModelArguments,\n",
    "    SWEEnv,\n",
    "    get_data_path_name,\n",
    ")\n",
    "from swebench import KEY_INSTANCE_ID, KEY_MODEL, KEY_PREDICTION\n",
    "from unidiff import PatchSet\n",
    "\n",
    "from sweagent.environment.utils import InvalidGithubURL, get_associated_commit_urls, get_gh_issue_data, parse_gh_issue_url\n",
    "from sweagent.environment.swe_env import SWEEnv\n",
    "from typing import Dict, Optional, Any\n",
    "from SweUserProxy import SweUserProxy\n",
    "import autogen\n",
    "\n",
    "__doc__: str = \"\"\" Run inference. Usage examples:\n",
    "\n",
    "```bash\n",
    "# Run over a github issue:\n",
    "python run.py --model_name \"gpt4\" --data_path \"https://github.com/pvlib/pvlib-python/issues/1603\" --config_file \"SWE-agent/config/default_from_url.yaml\"\n",
    "# Apply a patch in a local repository to an issue specified as Markdown file and run a custom installer script in the container\n",
    "python run.py --model_name \"gpt4\" --data_path \"/path/to/my_issue.md\" --repo_path \"/path/to/my/local/repo\" --environment_setup \"/path/to/setup.sh\" --config_file \"SWE-agent/config/default_from_url.yaml\" --apply_patch_locally\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "handler = RichHandler(show_time=False, show_path=False)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(\"run_dev\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "logger.propagate = False\n",
    "logging.getLogger(\"simple_parsing\").setLevel(logging.WARNING)\n",
    "\n",
    "def solve_autogen(\n",
    "    env: SWEEnv,\n",
    "    setup_args: Dict[str, Any],\n",
    "    observation: Optional[str] = None, \n",
    "    config_path: Optional[str] = None,   \n",
    "    agseed: Optional[int] = 1,\n",
    "):\n",
    "\n",
    "    config_list = autogen.config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "    )\n",
    "    \n",
    "    swe_user_proxy = SweUserProxy(\n",
    "        name=\"SweUserProxy\",\n",
    "        code_execution_config={\n",
    "            \"work_dir\": \"_output\", \"use_docker\": False\n",
    "        },\n",
    "        max_consecutive_auto_reply = 30,\n",
    "        human_input_mode=\"NEVER\",\n",
    "        setup_args=setup_args,\n",
    "        env=env, \n",
    "        config_path = config_path\n",
    "    )\n",
    "    assistant = autogen.AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        system_message=swe_user_proxy.system_msg,\n",
    "        llm_config={\n",
    "            \"timeout\": 600,\n",
    "            \"seed\": agseed,\n",
    "            \"config_list\": config_list,\n",
    "            \"cache_seed\": None,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    patch, history = swe_user_proxy.initiate_chat(\n",
    "        recipient=assistant,\n",
    "        initial_observation=observation,\n",
    "        cache_seed=None\n",
    "    )\n",
    "    print(\"--------------------------- cost ---------------------------\")\n",
    "    print(\"Actual usage summary for assistant (excluding completion from cache):\", assistant.get_actual_usage())\n",
    "    print(\"Total usage summary for assistant (including completion from cache):\", assistant.get_total_usage())\n",
    "\n",
    "    print(\"Actual usage summary for ai_user_proxy:\", swe_user_proxy.get_actual_usage())\n",
    "    print(\"Total usage summary for ai_user_proxy:\", swe_user_proxy.get_total_usage())\n",
    "\n",
    "    print(\"Actual usage summary for user_proxy:\", swe_user_proxy.get_actual_usage())\n",
    "    print(\"Total usage summary for user_proxy:\", swe_user_proxy.get_total_usage())\n",
    "    return patch, history\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ActionsArguments(FlattenedAccess, FrozenSerializable):\n",
    "    \"\"\"Run real-life actions (opening PRs, etc.) if we can solve the issue.\"\"\"\n",
    "    # Open a PR with the patch if we can solve the issue\n",
    "    open_pr: bool = False  \n",
    "    # When working with local repository: Apply patch\n",
    "    apply_patch_locally: bool = False\n",
    "    # Option to be used with open_pr: Skip action if there are already commits claiming \n",
    "    # to fix the issue. Please only set this to False if you are sure the commits are \n",
    "    # not fixes or if this is your own repository!\n",
    "    skip_if_commits_reference_issue: bool = True  \n",
    "    # OBSOLETE. Do not use, will raise error. Please specify --repo_path instead.\n",
    "    push_gh_repo_url: str = \"\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.push_gh_repo_url:\n",
    "            raise ValueError(\"push_gh_repo_url is obsolete. Use repo_path instead\")\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ScriptArguments(FlattenedAccess, FrozenSerializable):\n",
    "    \"\"\"Configure the control flow of the run.py script\"\"\"\n",
    "    environment: EnvironmentArguments\n",
    "    agent: AgentArguments\n",
    "    actions: ActionsArguments\n",
    "    instance_filter: str = \".*\"  # Only run instances that completely match this regex\n",
    "    skip_existing: bool = True  # Skip instances with existing trajectories\n",
    "    suffix: str = \"\"\n",
    "    # Raise unhandled exceptions during the run (useful for debugging)\n",
    "    raise_exceptions: bool = False\n",
    "    pred_dir: str = \"default\"\n",
    "    agseed: int = 1\n",
    "\n",
    "    @property\n",
    "    def run_name(self):\n",
    "        \"\"\"Generate a unique name for this run based on the arguments.\"\"\"\n",
    "        model_name = self.agent.model.model_name.replace(\":\", \"-\")\n",
    "        data_stem = get_data_path_name(self.environment.data_path)\n",
    "        assert self.agent.config_file is not None  # mypy\n",
    "        config_stem = Path(self.agent.config_file).stem\n",
    "\n",
    "        temp = self.agent.model.temperature\n",
    "        top_p = self.agent.model.top_p\n",
    "\n",
    "        per_instance_cost_limit = self.agent.model.per_instance_cost_limit\n",
    "        install_env = self.environment.install_environment\n",
    "\n",
    "        return (\n",
    "            f\"{model_name}__{data_stem}__{config_stem}__t-{temp:.2f}__p-{top_p:.2f}\"\n",
    "            + f\"__c-{per_instance_cost_limit:.2f}__install-{int(install_env)}\"\n",
    "            + (f\"__{self.suffix}\" if self.suffix else \"\")\n",
    "        )\n",
    "\n",
    "\n",
    "class _ContinueLoop(Exception):\n",
    "    \"\"\"Used for internal control flow\"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "class MainHook:\n",
    "    \"\"\"Hook structure for the web server or other addons to interface with\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_promising_patch(info: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Do we actually believe that the patch will solve the issue?\n",
    "        Or are we just submitting the last patch we generated before hitting an error?\n",
    "        \"\"\"\n",
    "        # The exit status can also be `submitted (exit_cost)` etc.\n",
    "        return info[\"exit_status\"] == \"submitted\" and info.get(\"submission\") is not None\n",
    "\n",
    "\n",
    "    def on_init(self, *, args: ScriptArguments, agent: Agent, env: SWEEnv, traj_dir: Path):\n",
    "        \"\"\"Called when hook is initialized\"\"\"\n",
    "        ...\n",
    "\n",
    "    def on_start(self):\n",
    "        \"\"\"Called at the beginning of `Main.main`\"\"\"\n",
    "        ... \n",
    "\n",
    "    def on_end(self):\n",
    "        \"\"\"Called at the end of `Main.main`\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def on_instance_start(self, *, index: int, instance: Dict[str, Any]):\n",
    "        \"\"\"Called at the beginning of each instance loop in `Main.run`\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def on_instance_skipped(self, ):\n",
    "        \"\"\"Called when an instance is skipped in `Main.run`\"\"\"\n",
    "        ...\n",
    "    \n",
    "    def on_instance_completed(self, *, info, trajectory):\n",
    "        \"\"\"Called when an instance is completed in `Main.run`\"\"\"\n",
    "        ...\n",
    "\n",
    "class SaveApplyPatchHook(MainHook):\n",
    "    \"\"\"This hook saves patches to a separate directory and optionally applies them to a local repository.\"\"\"\n",
    "\n",
    "    def on_init(self, *, args: ScriptArguments, agent: Agent, env: SWEEnv, traj_dir: Path):\n",
    "        self._traj_dir = traj_dir\n",
    "        self._apply_patch_locally = args.actions.apply_patch_locally\n",
    "        self._instance = None\n",
    "    \n",
    "    def on_instance_start(self, *, index: int, instance: Dict[str, Any]):\n",
    "        self._instance = instance\n",
    "    \n",
    "    def on_instance_completed(self, *, info, trajectory):\n",
    "        assert self._instance is not None # mypy\n",
    "        instance_id = self._instance[\"instance_id\"]\n",
    "        patch_path = self._save_patch(instance_id, info)\n",
    "        if patch_path:\n",
    "            if not self._apply_patch_locally:\n",
    "                return\n",
    "            if not self._is_promising_patch(info):\n",
    "                return\n",
    "            assert self._instance  # mypy\n",
    "            if not self._instance[\"repo_type\"] == \"local\":\n",
    "                return\n",
    "            local_dir = Path(self._instance[\"repo\"])\n",
    "            self._apply_patch(patch_path, local_dir)\n",
    "\n",
    "    @staticmethod\n",
    "    def _print_patch_message(patch_output_file: Path):\n",
    "        console = rich.console.Console()\n",
    "        msg = [\n",
    "            \"SWE-agent has produced a patch that it believes will solve the issue you submitted!\",\n",
    "            \"Use the code snippet below to inspect or apply it!\"\n",
    "        ]\n",
    "        panel = rich.panel.Panel.fit(\n",
    "            \"\\n\".join(msg),\n",
    "            title=\"🎉 Submission successful 🎉\",\n",
    "        )\n",
    "        console.print(panel)\n",
    "        content = [\n",
    "            \"```bash\",\n",
    "            f\"# The patch has been saved to your local filesystem at:\",\n",
    "            f\"PATCH_FILE_PATH='{patch_output_file.resolve()}'\",\n",
    "            \"# Inspect it:\",\n",
    "            \"cat \\\"${PATCH_FILE_PATH}\\\"\",\n",
    "            \"# Apply it to a local repository:\",\n",
    "            f\"cd <your local repo root>\",\n",
    "            \"git apply \\\"${PATCH_FILE_PATH}\\\"\",\n",
    "            \"```\",\n",
    "        ]\n",
    "        console.print(rich.markdown.Markdown(\"\\n\".join(content)))\n",
    "\n",
    "    def _save_patch(self, instance_id: str, info) -> Optional[Path]:\n",
    "        \"\"\"Create patch files that can be applied with `git am`.\n",
    "        \n",
    "        Returns:\n",
    "            The path to the patch file, if it was saved. Otherwise, returns None.\n",
    "        \"\"\"\n",
    "        patch_output_dir = self._traj_dir / \"patches\"\n",
    "        patch_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        patch_output_file = patch_output_dir / f\"{instance_id}.patch\"\n",
    "        if not info.get(\"submission\"):\n",
    "            logger.info(\"No patch to save.\")\n",
    "            return\n",
    "        model_patch = info[\"submission\"]\n",
    "        patch_output_file.write_text(model_patch)\n",
    "        if self._is_promising_patch(info):\n",
    "            # Only print big congratulations if we actually believe \n",
    "            # the patch will solve the issue\n",
    "            self._print_patch_message(patch_output_file)\n",
    "        return patch_output_file\n",
    "        \n",
    "    def _apply_patch(self, patch_file: Path, local_dir: Path) -> None:\n",
    "        \"\"\"Apply a patch to a local directory.\"\"\"\n",
    "        \n",
    "        assert local_dir.is_dir()\n",
    "        assert patch_file.exists()\n",
    "        # The resolve() is important, because we're gonna run the cmd\n",
    "        # somewhere else\n",
    "        cmd = [\"git\", \"apply\", str(patch_file.resolve())]\n",
    "        try:\n",
    "            subprocess.run(cmd, cwd=local_dir, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logger.error(f\"Failed to apply patch {patch_file} to {local_dir}: {e}\")\n",
    "            return\n",
    "        logger.info(f\"Applied patch {patch_file} to {local_dir}\")\n",
    "\n",
    "\n",
    "class OpenPRHook(MainHook):\n",
    "    \"\"\"This hook opens a PR if the issue is solved and the user has enabled the option.\"\"\"\n",
    "\n",
    "    def on_init(self, *, args: ScriptArguments, agent: Agent, env: SWEEnv, traj_dir: Path):\n",
    "        self._env = env\n",
    "        self._token: str = env._github_token\n",
    "        self._data_path = args.environment.data_path\n",
    "        self._open_pr = args.actions.open_pr\n",
    "        self._skip_if_commits_reference_issue = args.actions.skip_if_commits_reference_issue\n",
    "\n",
    "    def on_instance_completed(self, *, info, trajectory):\n",
    "        if self._open_pr and self.should_open_pr(info):\n",
    "            self._env.open_pr(trajectory=trajectory)\n",
    "    \n",
    "    def should_open_pr(self, info: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Does opening a PR make sense?\"\"\"\n",
    "        if not info.get(\"submission\"):\n",
    "            logger.info(\"Not opening PR because no submission was made.\")\n",
    "            return False\n",
    "        if info[\"exit_status\"] != \"submitted\":\n",
    "            logger.info(\"Not opening PR because exit status was %s and not submitted.\", info[\"exit_status\"])\n",
    "            return False\n",
    "        try:\n",
    "            issue = get_gh_issue_data(self._data_path, token=self._token)\n",
    "        except InvalidGithubURL:\n",
    "            logger.info(\"Currently only GitHub is supported to open PRs to. Skipping PR creation.\")\n",
    "            return False\n",
    "        if issue.state != \"open\":\n",
    "            logger.info(f\"Issue is not open (state={issue.state}. Skipping PR creation.\")\n",
    "            return False\n",
    "        if issue.assignee:\n",
    "            logger.info(\"Issue is already assigned. Skipping PR creation. Be nice :)\")\n",
    "            return False\n",
    "        if issue.locked:\n",
    "            logger.info(\"Issue is locked. Skipping PR creation.\")\n",
    "            return False\n",
    "        org, repo, issue_number = parse_gh_issue_url(self._data_path)\n",
    "        associated_commits = get_associated_commit_urls(org, repo, issue_number, token=self._token) \n",
    "        if associated_commits:\n",
    "            commit_url_strs = \", \".join(associated_commits)\n",
    "            if self._skip_if_commits_reference_issue:\n",
    "                logger.info(f\"Issue already has associated commits (see {commit_url_strs}). Skipping PR creation.\")\n",
    "                return False\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    \"Proceeding with PR creation even though there are already commits \"\n",
    "                    f\"({commit_url_strs}) associated with the issue. Please only do this for your own repositories \"\n",
    "                    \"or after verifying that the existing commits do not fix the issue.\"\n",
    "                )\n",
    "        return True\n",
    "\n",
    "\n",
    "class Main:\n",
    "    def __init__(self, args: ScriptArguments):\n",
    "        logger.info(f\"📙 Arguments: {args.dumps_yaml()}\")\n",
    "        self.args = args\n",
    "        self.agent = Agent(\"primary\", args.agent)\n",
    "        self.env = SWEEnv(args.environment)\n",
    "        # self.traj_dir = Path(\"trajectories\") / Path(getuser()) / args.run_name\n",
    "        self.traj_dir = Path(\"trajectories\") / args.pred_dir / args.run_name\n",
    "        self.traj_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self._save_arguments()\n",
    "        default_hooks = [\n",
    "            SaveApplyPatchHook(),\n",
    "            OpenPRHook(),\n",
    "        ]\n",
    "        self.hooks: List[MainHook] = []\n",
    "        for hook in default_hooks:\n",
    "            self.add_hook(hook)\n",
    "    \n",
    "    def add_hook(self, hook: MainHook):\n",
    "        hook.on_init(args=self.args, agent=self.agent, env=self.env, traj_dir=self.traj_dir)\n",
    "        self.hooks.append(hook)\n",
    "\n",
    "    def run(self, index):\n",
    "        # Reset environment\n",
    "        instance_id = self.env.data[index][\"instance_id\"]\n",
    "        for hook in self.hooks:\n",
    "            hook.on_instance_start(index=index, instance=self.env.data[index])\n",
    "        assert isinstance(instance_id, str)  # mypy\n",
    "        if self.should_skip(instance_id):\n",
    "            for hook in self.hooks:\n",
    "                hook.on_instance_skipped()\n",
    "            raise _ContinueLoop\n",
    "        logger.info(\"▶️  Beginning task \" + str(index))\n",
    "\n",
    "        observation, info = self.env.reset(index)\n",
    "        if info is None:\n",
    "            raise _ContinueLoop\n",
    "\n",
    "        # Get info, patch information\n",
    "        issue = getattr(self.env, \"query\", None)\n",
    "        files = []\n",
    "        assert self.env.record is not None  # mypy\n",
    "        if \"patch\" in self.env.record:\n",
    "            files = \"\\n\".join(\n",
    "                [f\"- {x.path}\" for x in PatchSet(self.env.record[\"patch\"]).modified_files]\n",
    "            )\n",
    "        # Get test files, F2P tests information\n",
    "        test_files = []\n",
    "        if \"test_patch\" in self.env.record:\n",
    "            test_patch_obj = PatchSet(self.env.record[\"test_patch\"])\n",
    "            test_files = \"\\n\".join(\n",
    "                [f\"- {x.path}\" for x in test_patch_obj.modified_files + test_patch_obj.added_files]\n",
    "            )\n",
    "        tests = \"\"\n",
    "        if \"FAIL_endTO_PASS\" in self.env.record:\n",
    "            tests = \"\\n\".join([f\"- {x}\" for x in self.env.record[\"FAIL_TO_PASS\"]])\n",
    "\n",
    "        setup_args = {\n",
    "            \"issue\": issue,\n",
    "            \"files\": files,\n",
    "            \"test_files\": test_files,\n",
    "            \"tests\": tests\n",
    "        }\n",
    "        info, history = solve_autogen(\n",
    "            setup_args=setup_args,\n",
    "            env=self.env,\n",
    "            observation=observation,\n",
    "            config_path = \"./default.yaml\",\n",
    "            agseed = self.args.agseed\n",
    "        )\n",
    "        self._save_history(instance_id, history)\n",
    "        self._save_predictions(instance_id, info)\n",
    "        for hook in self.hooks:\n",
    "            hook.on_instance_completed(info=info, trajectory=None)\n",
    "\n",
    "    def main(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.on_start()\n",
    "        # length = len(self.env.data)\n",
    "        # length = 2\n",
    "        for index in range(len(self.env.data)):\n",
    "            try:\n",
    "                self.run(index)\n",
    "            except _ContinueLoop:\n",
    "                continue\n",
    "            except KeyboardInterrupt:\n",
    "                logger.info(\"Exiting InterCode environment...\")\n",
    "                self.env.close()\n",
    "                break\n",
    "            except SystemExit:\n",
    "                logger.critical(f\"❌ Exiting because SystemExit was called\")\n",
    "                self.env.close()\n",
    "                logger.info(\"Container closed\")\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                if self.args.raise_exceptions:\n",
    "                    self.env.close()\n",
    "                    raise e\n",
    "                if self.env.record:\n",
    "                    logger.warning(f\"❌ Failed on {self.env.record['instance_id']}: {e}\")\n",
    "                else:\n",
    "                    logger.warning(f\"❌ Failed on unknown instance\")\n",
    "                self.env.reset_container()\n",
    "                continue\n",
    "        for hook in self.hooks:\n",
    "            hook.on_end()\n",
    "\n",
    "    \n",
    "    def _save_arguments(self) -> None:\n",
    "        \"\"\"Save the arguments to a yaml file to the run's trajectory directory.\"\"\"\n",
    "        log_path = self.traj_dir / \"args.yaml\"\n",
    "\n",
    "        if log_path.exists():\n",
    "            try:\n",
    "                other_args = self.args.load_yaml(log_path)\n",
    "                if (self.args.dumps_yaml() != other_args.dumps_yaml()):  # check yaml equality instead of object equality\n",
    "                    logger.warning(\"**************************************************\")\n",
    "                    logger.warning(\"Found existing args.yaml with different arguments!\")\n",
    "                    logger.warning(\"**************************************************\")\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to load existing args.yaml: {e}\")\n",
    "\n",
    "        with log_path.open(\"w\") as f:\n",
    "            self.args.dump_yaml(f)\n",
    "\n",
    "\n",
    "    def should_skip(self, instance_id: str) -> bool:\n",
    "        \"\"\"Check if we should skip this instance based on the instance filter and skip_existing flag.\"\"\"\n",
    "        if re.match(self.args.instance_filter, instance_id) is None:\n",
    "            logger.info(f\"Instance filter not matched. Skipping instance {instance_id}\")\n",
    "            return True\n",
    "\n",
    "        # If flag is set to False, don't skip\n",
    "        if not self.args.skip_existing:\n",
    "            return False\n",
    "\n",
    "        # Check if there's an existing trajectory for this instance\n",
    "        log_path = self.traj_dir / (instance_id + \".traj\")\n",
    "        if log_path.exists():\n",
    "            with log_path.open(\"r\") as f:\n",
    "                data = json.load(f)\n",
    "            # If the trajectory has no exit status, it's incomplete and we will redo it\n",
    "            exit_status = data[\"info\"].get(\"exit_status\", None)\n",
    "            if exit_status == \"early_exit\" or exit_status is None:\n",
    "                logger.info(f\"Found existing trajectory with no exit status: {log_path}\")\n",
    "                logger.info(\"Removing incomplete trajectory...\")\n",
    "                os.remove(log_path)\n",
    "            else:\n",
    "                logger.info(f\"⏭️ Skipping existing trajectory: {log_path}\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _save_history(self, instance_id, history):\n",
    "        history_output_dir = self.traj_dir / \"histories\"\n",
    "        history_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "        history_output_file = history_output_dir / f\"{instance_id}.json\"\n",
    "        with history_output_file.open(\"w\") as f:\n",
    "            json.dump(history, f)\n",
    "        logger.info(f\"Saved history to {history_output_file}\")\n",
    "        \n",
    "    def _save_predictions(self, instance_id: str, info):\n",
    "        output_file = self.traj_dir / \"all_preds.jsonl\"\n",
    "        model_patch = info[\"submission\"] if \"submission\" in info else None\n",
    "        datum = {\n",
    "            KEY_MODEL: Path(self.traj_dir).name,\n",
    "            KEY_INSTANCE_ID: instance_id,\n",
    "            KEY_PREDICTION: model_patch,\n",
    "        }\n",
    "        with open(output_file, \"a+\") as fp:\n",
    "            print(json.dumps(datum), file=fp, flush=True)\n",
    "        logger.info(f\"Saved predictions to {output_file}\")\n",
    "\n",
    "\n",
    "def get_args(args=None) -> ScriptArguments:\n",
    "    \"\"\"Parse command line arguments and return a ScriptArguments object.\n",
    "    \n",
    "    Args:\n",
    "        args: Optional list of arguments to parse. If not provided, uses sys.argv.\n",
    "    \"\"\"\n",
    "    defaults = ScriptArguments(\n",
    "        suffix=\"\",\n",
    "        environment=EnvironmentArguments(\n",
    "            image_name=\"sweagent/swe-agent:latest\",\n",
    "            data_path=\"princeton-nlp/SWE-bench_Lite\",\n",
    "            split=\"test\",\n",
    "            verbose=True,\n",
    "            install_environment=True,\n",
    "        ),\n",
    "        skip_existing=True,\n",
    "        agent=AgentArguments(\n",
    "            model=ModelArguments(\n",
    "                model_name=\"gpt4\",\n",
    "                total_cost_limit=0.0,\n",
    "                per_instance_cost_limit=3.0,\n",
    "                temperature=0.0,\n",
    "                top_p=0.95,\n",
    "            ),\n",
    "            config_file=Path(\"./default.yaml\"),\n",
    "        ),\n",
    "        actions=ActionsArguments(open_pr=False, skip_if_commits_reference_issue=True),\n",
    "    )\n",
    "\n",
    "    # Nicer yaml dumping of multiline strings\n",
    "    def multiline_representer(dumper, data):\n",
    "        \"\"\"configures yaml for dumping multiline strings\n",
    "        Ref: https://stackoverflow.com/questions/8640959/how-can-i-control-what-scalar-form-pyyaml-uses-for-my-data\n",
    "        \"\"\"\n",
    "        if data.count(\"\\n\") > 0:  # check for multiline string\n",
    "            return dumper.represent_scalar(\"tag:yaml.org,2002:str\", data, style=\"|\")\n",
    "        return dumper.represent_scalar(\"tag:yaml.org,2002:str\", data)\n",
    "\n",
    "    yaml.add_representer(str, multiline_representer)\n",
    "\n",
    "    return parse(ScriptArguments, default=defaults, add_config_path_arg=False, args=args, formatter_class=RichHelpFormatter, description=Markdown(__doc__))\n",
    "\n",
    "def main(args: ScriptArguments):\n",
    "    Main(args).main()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(get_args())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
