{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Anthropic Claude\n",
    "\n",
    "In the v0.2.30 release of AutoGen we support Anthropic Client.\n",
    "\n",
    "Claude is a family of large language models developed by Anthropic and designed to revolutionize the way you interact with AI. Claude excels at a wide variety of tasks involving language, reasoning, analysis, coding, and more. The models are highly capable, easy to use, and can be customized to suit your needs.\n",
    "\n",
    "In this notebook, we demonstrate how to use Anthropic Claude model for AgentChat in AutoGen.\n",
    "\n",
    "## Features\n",
    "\n",
    "Additionally, this client class provides support for function/tool calling and will track token usage and cost correctly as per Anthropic's API costs (as of June 2024).\n",
    "\n",
    "## Requirements\n",
    "To use Anthropic Claude with AutoGen, first you need to install the `pyautogen[\"anthropic]` package.\n",
    "\n",
    "To try out the function call feature of Claude model, you need to install `anthropic>=0.23.1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyautogen\n",
    "!pip install pyautogen[\"anthropic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the config for the Anthropic API\n",
    "\n",
    "You can add any parameters that are needed for the custom model loading in the same configuration list.\n",
    "\n",
    "It is important to add the `api_type` field and set it to a string that corresponds to the client type used: `anthropic`.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"model\": \"claude-3-sonnet-20240229\",\n",
    "        \"api_key\": \"your Anthropic API Key goes here\",\n",
    "        \"api_type\": \"anthropic\",\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2, # Note: It is recommended to set temperature or top_p but not both.\n",
    "        \"max_tokens\": 10000,\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-3-opus-20240229\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-2.0\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-2.1\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "    {\n",
    "        \"model\":\"claude-3.0-haiku\",\n",
    "        \"api_key\":\"your api key\",\n",
    "        \"api_type\":\"anthropic\",\n",
    "    },\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative\n",
    "\n",
    "As an alternative to the api_key key and value in the config, you can set the environment variable `ANTHROPIC_API_KEY` to your Anthropic API key.\n",
    "\n",
    "Linux/Mac:\n",
    "```\n",
    "export ANTHROPIC_API_KEY=\"your Anthropic API key here\"\n",
    "```\n",
    "Windows:\n",
    "```\n",
    "set ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list_claude = [\n",
    "    {\n",
    "        # Choose your model name.\n",
    "        \"model\": \"claude-3-5-sonnet-20240620\",\n",
    "        # You need to provide your API key here.\n",
    "        \"api_key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        \"api_type\": \"anthropic\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Example with Two Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "Construct a simple conversation between a User proxy and an ConversableAgent based on Claude-3 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = autogen.AssistantAgent(\n",
    "    \"assistant\",\n",
    "    llm_config={\n",
    "        \"config_list\": config_list_claude,\n",
    "    },\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    \"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    max_consecutive_auto_reply=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Write a python program to print the first 10 numbers of the Fibonacci sequence.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Certainly! I'll write a Python program to print the first 10 numbers of the Fibonacci sequence. Here's the code:\n",
      "\n",
      "```python\n",
      "# filename: fibonacci.py\n",
      "\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    \n",
      "    while len(fib_sequence) < n:\n",
      "        next_num = fib_sequence[-1] + fib_sequence[-2]\n",
      "        fib_sequence.append(next_num)\n",
      "    \n",
      "    return fib_sequence\n",
      "\n",
      "# Print the first 10 numbers of the Fibonacci sequence\n",
      "n = 10\n",
      "result = fibonacci(n)\n",
      "print(f\"The first {n} numbers of the Fibonacci sequence are:\")\n",
      "print(result)\n",
      "```\n",
      "\n",
      "This Python script does the following:\n",
      "\n",
      "1. We define a function called `fibonacci` that takes an argument `n`, which is the number of Fibonacci numbers we want to generate.\n",
      "2. Inside the function, we initialize the sequence with the first two numbers: [0, 1].\n",
      "3. We use a while loop to generate subsequent numbers until we reach the desired length `n`.\n",
      "4. Each new number is the sum of the two preceding numbers.\n",
      "5. We append each new number to the `fib_sequence` list.\n",
      "6. After generating the sequence, we return it.\n",
      "7. Outside the function, we set `n = 10` to get the first 10 numbers.\n",
      "8. We call the `fibonacci` function with `n = 10` and store the result.\n",
      "9. Finally, we print the result.\n",
      "\n",
      "You can save this code in a file named `fibonacci.py` and then run it. The program will output the first 10 numbers of the Fibonacci sequence.\n",
      "\n",
      "Let's execute this code and see the result:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "The first 10 numbers of the Fibonacci sequence are:\n",
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingyunwu/Documents/github/autogen/autogen/oai/anthropic.py:272: UserWarning: Cost calculation not available for model claude-3-5-sonnet-20240620\n",
      "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great! The code executed successfully, and we have the correct output. Let's verify the result:\n",
      "\n",
      "The first 10 numbers of the Fibonacci sequence are indeed:\n",
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "\n",
      "This is correct because:\n",
      "1. The sequence starts with 0 and 1.\n",
      "2. Each subsequent number is the sum of the two preceding numbers:\n",
      "   - 1 = 0 + 1\n",
      "   - 2 = 1 + 1\n",
      "   - 3 = 1 + 2\n",
      "   - 5 = 2 + 3\n",
      "   - 8 = 3 + 5\n",
      "   - 13 = 5 + 8\n",
      "   - 21 = 8 + 13\n",
      "   - 34 = 13 + 21\n",
      "\n",
      "The program has successfully generated and printed the first 10 numbers of the Fibonacci sequence. The task is complete, and the result is verified to be correct.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Write a python program to print the first 10 numbers of the Fibonacci sequence.', 'role': 'assistant'}, {'content': 'Certainly! I\\'ll write a Python program to print the first 10 numbers of the Fibonacci sequence. Here\\'s the code:\\n\\n```python\\n# filename: fibonacci.py\\n\\ndef fibonacci(n):\\n    fib_sequence = [0, 1]\\n    \\n    while len(fib_sequence) < n:\\n        next_num = fib_sequence[-1] + fib_sequence[-2]\\n        fib_sequence.append(next_num)\\n    \\n    return fib_sequence\\n\\n# Print the first 10 numbers of the Fibonacci sequence\\nn = 10\\nresult = fibonacci(n)\\nprint(f\"The first {n} numbers of the Fibonacci sequence are:\")\\nprint(result)\\n```\\n\\nThis Python script does the following:\\n\\n1. We define a function called `fibonacci` that takes an argument `n`, which is the number of Fibonacci numbers we want to generate.\\n2. Inside the function, we initialize the sequence with the first two numbers: [0, 1].\\n3. We use a while loop to generate subsequent numbers until we reach the desired length `n`.\\n4. Each new number is the sum of the two preceding numbers.\\n5. We append each new number to the `fib_sequence` list.\\n6. After generating the sequence, we return it.\\n7. Outside the function, we set `n = 10` to get the first 10 numbers.\\n8. We call the `fibonacci` function with `n = 10` and store the result.\\n9. Finally, we print the result.\\n\\nYou can save this code in a file named `fibonacci.py` and then run it. The program will output the first 10 numbers of the Fibonacci sequence.\\n\\nLet\\'s execute this code and see the result:', 'role': 'user'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\nThe first 10 numbers of the Fibonacci sequence are:\\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n', 'role': 'assistant'}, {'content': \"Great! The code executed successfully, and we have the correct output. Let's verify the result:\\n\\nThe first 10 numbers of the Fibonacci sequence are indeed:\\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n\\nThis is correct because:\\n1. The sequence starts with 0 and 1.\\n2. Each subsequent number is the sum of the two preceding numbers:\\n   - 1 = 0 + 1\\n   - 2 = 1 + 1\\n   - 3 = 1 + 2\\n   - 5 = 2 + 3\\n   - 8 = 3 + 5\\n   - 13 = 5 + 8\\n   - 21 = 8 + 13\\n   - 34 = 13 + 21\\n\\nThe program has successfully generated and printed the first 10 numbers of the Fibonacci sequence. The task is complete, and the result is verified to be correct.\\n\\nTERMINATE\", 'role': 'user'}], summary=\"Great! The code executed successfully, and we have the correct output. Let's verify the result:\\n\\nThe first 10 numbers of the Fibonacci sequence are indeed:\\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\\n\\nThis is correct because:\\n1. The sequence starts with 0 and 1.\\n2. Each subsequent number is the sum of the two preceding numbers:\\n   - 1 = 0 + 1\\n   - 2 = 1 + 1\\n   - 3 = 1 + 2\\n   - 5 = 2 + 3\\n   - 8 = 3 + 5\\n   - 13 = 5 + 8\\n   - 21 = 8 + 13\\n   - 34 = 13 + 21\\n\\nThe program has successfully generated and printed the first 10 numbers of the Fibonacci sequence. The task is complete, and the result is verified to be correct.\\n\\n\", cost={'usage_including_cached_inference': {'total_cost': 0.0, 'claude-3-5-sonnet-20240620': {'cost': 0.0, 'prompt_tokens': 1457, 'completion_tokens': 645, 'total_tokens': 2102}}, 'usage_excluding_cached_inference': {'total_cost': 0.0, 'claude-3-5-sonnet-20240620': {'cost': 0.0, 'prompt_tokens': 1457, 'completion_tokens': 645, 'total_tokens': 2102}}}, human_input=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant, message=\"Write a python program to print the first 10 numbers of the Fibonacci sequence.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Call in Latest Anthropic API \n",
    "Anthropic just announced that tool use is now supported in the Anthropic API. To use this feature, please install `anthropic>=0.23.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@user_proxy.register_for_execution()  # Decorator factory for registering a function to be executed by an agent\n",
    "@assistant.register_for_llm(\n",
    "    name=\"get_weather\", description=\"Get the current weather in a given location.\"\n",
    ")  # Decorator factory for registering a function to be used by an agent\n",
    "def preprocess(location: Annotated[str, \"The city and state, e.g. Toronto, ON.\"]) -> str:\n",
    "    return \"Absolutely cloudy and rainy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What's the weather in Toronto?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function call: get_weather *****\u001b[0m\n",
      "Arguments: \n",
      "{\"location\": \"Toronto, ON\"}\n",
      "\u001b[32m************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_weather...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[runtime logging] log_function_use: autogen logger is None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling function (get_weather) *****\u001b[0m\n",
      "Absolutely cloudy and rainy\n",
      "\u001b[32m********************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the result from the `get_weather` function, I can provide you with the current weather information for Toronto:\n",
      "\n",
      "The weather in Toronto is currently absolutely cloudy and rainy.\n",
      "\n",
      "This means that:\n",
      "1. The sky is completely covered with clouds, with no visible clear patches.\n",
      "2. It is currently raining in Toronto.\n",
      "\n",
      "If you're in Toronto or planning to go there, you should be prepared for wet conditions. It would be advisable to:\n",
      "- Carry an umbrella\n",
      "- Wear waterproof clothing or a raincoat\n",
      "- Use appropriate footwear for wet conditions\n",
      "- Be cautious while driving, as roads may be slippery\n",
      "\n",
      "Keep in mind that weather can change, so if you need more specific or updated information (like temperature, wind speed, or forecast), you might want to check a detailed weather report or ask for more specific weather data.\n",
      "\n",
      "Is there anything else you'd like to know about the weather in Toronto or any other location?\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': \"What's the weather in Toronto?\", 'role': 'assistant'}, {'function_call': {'arguments': '{\"location\": \"Toronto, ON\"}', 'name': 'get_weather'}, 'content': None, 'role': 'assistant'}, {'content': 'Absolutely cloudy and rainy', 'name': 'get_weather', 'role': 'function'}, {'content': \"Based on the result from the `get_weather` function, I can provide you with the current weather information for Toronto:\\n\\nThe weather in Toronto is currently absolutely cloudy and rainy.\\n\\nThis means that:\\n1. The sky is completely covered with clouds, with no visible clear patches.\\n2. It is currently raining in Toronto.\\n\\nIf you're in Toronto or planning to go there, you should be prepared for wet conditions. It would be advisable to:\\n- Carry an umbrella\\n- Wear waterproof clothing or a raincoat\\n- Use appropriate footwear for wet conditions\\n- Be cautious while driving, as roads may be slippery\\n\\nKeep in mind that weather can change, so if you need more specific or updated information (like temperature, wind speed, or forecast), you might want to check a detailed weather report or ask for more specific weather data.\\n\\nIs there anything else you'd like to know about the weather in Toronto or any other location?\\n\\nTERMINATE\", 'role': 'user'}], summary=\"Based on the result from the `get_weather` function, I can provide you with the current weather information for Toronto:\\n\\nThe weather in Toronto is currently absolutely cloudy and rainy.\\n\\nThis means that:\\n1. The sky is completely covered with clouds, with no visible clear patches.\\n2. It is currently raining in Toronto.\\n\\nIf you're in Toronto or planning to go there, you should be prepared for wet conditions. It would be advisable to:\\n- Carry an umbrella\\n- Wear waterproof clothing or a raincoat\\n- Use appropriate footwear for wet conditions\\n- Be cautious while driving, as roads may be slippery\\n\\nKeep in mind that weather can change, so if you need more specific or updated information (like temperature, wind speed, or forecast), you might want to check a detailed weather report or ask for more specific weather data.\\n\\nIs there anything else you'd like to know about the weather in Toronto or any other location?\\n\\n\", cost={'usage_including_cached_inference': {'total_cost': 0.0, 'claude-3-5-sonnet-20240620': {'cost': 0.0, 'prompt_tokens': 1821, 'completion_tokens': 311, 'total_tokens': 2132}}, 'usage_excluding_cached_inference': {'total_cost': 0.0, 'claude-3-5-sonnet-20240620': {'cost': 0.0, 'prompt_tokens': 1821, 'completion_tokens': 311, 'total_tokens': 2132}}}, human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What's the weather in Toronto?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Define and load a custom model",
   "tags": [
    "custom model"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
